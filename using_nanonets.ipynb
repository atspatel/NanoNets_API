{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is the simple steps to train model using NanoNets API\n",
    "\n",
    "Previously in blog, we have an intro to Object Detection and how to make predection on tensorflow pre-trained model.\n",
    "Tensorflow pre-trained model has been trained on [COCO dataset](http://cocodataset.org/) which has 90 different objects annotated.\n",
    "\n",
    "Now, what if you want to detect your choice of objects (may or may not be in 90 classes)? So here, we are going to discuss how can we make custom object detection model using simplest way and with less relative data.\n",
    "\n",
    "\n",
    "#### Step 1: Data Preparation\n",
    "\n",
    "What we need? Few images (around 100-200) and their object bounding box annotations. There are many ways to store bounding box annotation, but here I am using XML file to store annotation.\n",
    "\n",
    "Make a work directiory, and open this notebook in same diretory.\n",
    "keep all images in one floder and annotation(.xml) in other folder (name of annotation file should be same as corresponding name of image)\n",
    "\n",
    "Also need to have list of all objects (same name given in annotation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## change the folder path if needed\n",
    "image_folder = \"data/images\"\n",
    "annotation_folder = \"data/annotations\"\n",
    "object_list = [''] ## will refer as categories\n",
    "extentions = ['.png'] ## list of image extension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Create NanoNets Account\n",
    "\n",
    "To use NanoNets API to train model, you first need to create account on nanonets and get your api key from there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AUTH_KEY = \"\" ## put your api key here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### imports\n",
    "\n",
    "import requests, json, os\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### CONSTANTS\n",
    "BASE_URL = \"https://app.nanonets.com/api/v2/ObjectDetection/Model/\"\n",
    "MODEL_URL = \"https://app.nanonets.com/api/v2/ObjectDetection/Models/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Initialize new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_new_model(categories):\n",
    "    \"\"\" function will create a new model architecture for training\n",
    "    \n",
    "    Args:\n",
    "    categories: List of objects you want to predict\n",
    "    \n",
    "    return:\n",
    "    model_id: a unique reference to new created model\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    payload = json.dumps({\"categories\" : categories})\n",
    "    headers = {\n",
    "        'Content-Type': \"application/json\",\n",
    "        }\n",
    "\n",
    "    response = requests.request(\"POST\", BASE_URL, headers=headers, auth=requests.auth.HTTPBasicAuth(AUTH_KEY, ''), data=payload)\n",
    "\n",
    "    result = json.loads(response.text)\n",
    "    model_id, model_type, categories = (result[\"model_id\"], result[\"model_type\"], result[\"categories\"])\n",
    "    return model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a6b5947a-241a-41f1-af2d-54413722e16a\n"
     ]
    }
   ],
   "source": [
    "model_id = create_new_model(object_list)\n",
    "print model_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: upload data\n",
    "We have created a new model, now we need to uplaod the data to train model.\n",
    "Here is the code the upload and xml_file data to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model_info(model_id):\n",
    "    \"\"\"function to get information about model at any time\n",
    "    Args:\n",
    "    model_id: unique model_id generated at model creation time\n",
    "    \"\"\"\n",
    "    \n",
    "    response = requests.request('GET', '%s%s'%(BASE_URL, model_id), auth= requests.auth.HTTPBasicAuth(AUTH_KEY, ''))\n",
    "    print response.text\n",
    "    result = json.loads(response.text)\n",
    "    model_id, model_type, categories, state = (result[\"model_id\"], result[\"model_type\"], result[\"categories\"], result[\"state\"])\n",
    "    return model_id, model_type, categories, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_xml_file_name(image_file):\n",
    "    return os.path.join(annotation_folder, \"%s.xml\"%(image_file.rsplit('.', 1)[0]))\n",
    "\n",
    "def create_xml_to_object(image_file):\n",
    "    tree = ET.parse(get_xml_file_name(image_file))\n",
    "    root = tree.getroot()\n",
    "\n",
    "    object_list = []\n",
    "    \n",
    "    ### here if you find any problem here, just check with xml file format and change the code \n",
    "    ### to access member an elements \n",
    "    \n",
    "    for member in root.findall('object'):\n",
    "        label = member[0].text.lower()\n",
    "        bndbox = {}\n",
    "        bndbox['xmin'] = int(member[4][0].text)\n",
    "        bndbox['ymin'] = int(member[4][1].text)\n",
    "        bndbox['xmax'] = int(member[4][2].text)\n",
    "        bndbox['ymax'] = int(member[4][3].text)\n",
    "        object_list.append({'name': label, 'bndbox': bndbox})\n",
    "    return object_list\n",
    "\n",
    "def upload_objects_by_file(model_id):\n",
    "    image_count = 0\n",
    "    print \"uploading images....\"\n",
    "    for f in os.listdir(image_folder):\n",
    "        if not f.endswith(tuple(extentions)): continue\n",
    "        filename = os.path.join(image_folder, f)\n",
    "        file = open(filename, 'rb')\n",
    "\n",
    "        object_data = json.dumps(create_xml_to_object(f))\n",
    "\n",
    "        data = {'file' : file,\n",
    "                'data' :('', '[{\"filename\":\"%s\", \"object\": %s}]'%(f, object_data)),\n",
    "                'modelId' :('', '%s'%model_id)}\n",
    "        response = requests.post('%s%s/UploadFile/'%(BASE_URL, model_id), auth=requests.auth.HTTPBasicAuth(AUTH_KEY, ''), files=data)\n",
    "        image_count += 1\n",
    "    print \"Number of Uploaded Images : \", image_count\n",
    "    return get_model_info(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Uploaded Images :  197\n",
      "{\"model_id\":\"a6b5947a-241a-41f1-af2d-54413722e16a\",\"model_type\":\"localization\",\"state\":2,\"status\":\"Some data uploaded\",\"accuracy\":0,\"categories\":[{\"name\":\"signature\",\"count\":267}]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(u'a6b5947a-241a-41f1-af2d-54413722e16a',\n",
       " u'localization',\n",
       " [{u'count': 267, u'name': u'signature'}],\n",
       " 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upload_objects_by_file(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Train a model\n",
    "\n",
    "We have uploaded a data to model, now it's time to train a model. Run the code below, sit back and relax for some time. Training is going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model_id):\n",
    "\n",
    "    headers = {'authorization': 'Basic %s'%AUTH_KEY}\n",
    "    querystring = {'modelId': model_id}\n",
    "    response = requests.request('POST', '%s%s/Train/'%(BASE_URL, model_id), headers=headers, auth=requests.auth.HTTPBasicAuth(AUTH_KEY, ''), params=querystring)\n",
    "    print \"training started .... \"\n",
    "    print json.loads(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training started .... \n",
      "{u'status': u'In queue for training', u'model_id': u'a6b5947a-241a-41f1-af2d-54413722e16a', u'state': 3, u'model_type': u'localization', u'categories': [{u'count': 267, u'name': u'signature'}], u'accuracy': 0}\n"
     ]
    }
   ],
   "source": [
    "train_model(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While training is going on, you can check the state of model by `get_model_info` function. When training will finished, state of model will change to 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"model_id\":\"a6b5947a-241a-41f1-af2d-54413722e16a\",\"model_type\":\"localization\",\"state\":3,\"status\":\"In queue for training\",\"accuracy\":0,\"categories\":[{\"name\":\"signature\",\"count\":267}]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(u'a6b5947a-241a-41f1-af2d-54413722e16a',\n",
       " u'localization',\n",
       " [{u'count': 267, u'name': u'signature'}],\n",
       " 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_model_info(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step 6: It's time to predict\n",
    "\n",
    "Keep your test image ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_image_path = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_single_image(model_id, test_image_path):\n",
    "    if not test_image_path.endswith(tuple(extentions)):\n",
    "        print \"provide image with correct extentions\"\n",
    "        return 0\n",
    "    data = {'file': open(filepath, 'rb'),\n",
    "            'modelId': ('', '%s'%model_id)}\n",
    "    response = requests.post(url, auth=requests.auth.HTTPBasicAuth(AUTH_KEY, ''), files=data)\n",
    "    result = json.loads(response.text)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_single_image(model_id, test_image_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
